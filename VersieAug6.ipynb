{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 1: Dinsdag om 9.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after loading:\n",
      "                31/01/1995  28/02/1995  31/03/1995  30/04/1995  31/05/1995  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               30/06/1995  31/07/1995  31/08/1995  30/09/1995  31/10/1995  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  28/02/2023  31/03/2023  30/04/2023  31/05/2023  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               30/06/2023  31/07/2023  31/08/2023  30/09/2023  31/10/2023  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               30/11/2023  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data with datetime columns:\n",
      "                1995-01-31  1995-02-28  1995-03-31  1995-04-30  1995-05-31  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               1995-06-30  1995-07-31  1995-08-31  1995-09-30  1995-10-31  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  2023-02-28  2023-03-31  2023-04-30  2023-05-31  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               2023-06-30  2023-07-31  2023-08-31  2023-09-30  2023-10-31  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               2023-11-30  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data loaded with shape: (66, 347)\n",
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "Y_train_other shape: (54, 180)\n",
      "Y_reg_train shape: (66, 169)\n",
      "Y_train_other_std shape: (54, 180)\n",
      "Y_reg_train_std shape: (66, 169)\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "Shape of Y_train_other_std: (54, 180)\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shapes match, proceeding with dfm_fit_pcayw\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "Shape of X before transpose: (169, 66)\n",
      "Shape of Y before transpose: (180, 54)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of columns in X and Y must be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 158\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y_train_other_std\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m model\u001b[38;5;241m.\u001b[39mfactors\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes match, proceeding with dfm_fit_pcayw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m     B_matrix, C_matrix, r2_insample, beta_const \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdfm_fit_pcayw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_train_other_std\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_reg_train_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR2 insample: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_insample\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[14], line 96\u001b[0m, in \u001b[0;36mDynamicFactorModel.dfm_fit_pcayw\u001b[1;34m(self, data_train, data_train_reg)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myw_estimation()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB_mat, r2_insample, beta_const \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menet_fit(data_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactors\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m---> 96\u001b[0m C_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautoregression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta_const\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB_mat, C_matrix, r2_insample, beta_const\n",
      "Cell \u001b[1;32mIn[14], line 75\u001b[0m, in \u001b[0;36mDynamicFactorModel.autoregression\u001b[1;34m(self, data_train_reg, fac_train, beta_const)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of Y before transpose:\u001b[39m\u001b[38;5;124m\"\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of columns in X and Y must be the same\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Transpose and convert X and Y to matrices\u001b[39;00m\n\u001b[0;32m     78\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatrix(Y)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of columns in X and Y must be the same"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import copy\n",
    "\n",
    "# Standaardisatie functie uit utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def read_and_preprocess_data(path):\n",
    "    data = pd.read_excel(path, engine='openpyxl', index_col=0)\n",
    "    print(\"Data after loading:\\n\", data.head())  # Print first few rows to inspect\n",
    "\n",
    "    data.columns = pd.to_datetime(data.columns, format='%d/%m/%Y')\n",
    "    print(\"Data with datetime columns:\\n\", data.head())  # Print first few rows to inspect\n",
    "    print(\"Data loaded with shape:\", data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNet()\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        # Debug statements\n",
    "        print(\"Shape of X before transpose:\", X.shape)\n",
    "        print(\"Shape of Y before transpose:\", Y.shape)\n",
    "\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            raise ValueError(\"The number of columns in X and Y must be the same\")\n",
    "\n",
    "        # Transpose and convert X and Y to matrices\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        # Debug statements after transpose\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "FILE_PATH = r\"C:\\Thesis\\03. Data\\Final version data\\Static.xlsx\"\n",
    "\n",
    "df_data = read_and_preprocess_data(FILE_PATH)\n",
    "\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "print(\"Y_train_other shape:\", Y_train_other.shape)\n",
    "print(\"Y_reg_train shape:\", Y_reg_train.shape)\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "print(\"Y_reg_train_std shape:\", Y_reg_train_std.shape)\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Check lengths of the data to be passed to ElasticNet\n",
    "print(\"Shape of Y_train_other_std:\", Y_train_other_std.shape)\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "\n",
    "if Y_train_other_std.shape[0] == model.factors.T.shape[0]:\n",
    "    print(\"Shapes match, proceeding with dfm_fit_pcayw\")\n",
    "    B_matrix, C_matrix, r2_insample, beta_const = model.dfm_fit_pcayw(Y_train_other_std, Y_reg_train_std)\n",
    "    print(f'R2 insample: {r2_insample}')\n",
    "else:\n",
    "    print(\"Inconsistent lengths between Y_train_other_std en model.factors.T\")\n",
    "    print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "    print(\"model.factors.T shape:\", model.factors.T.shape)\n",
    "\n",
    "# Corrected matrix dimensions for predictions\n",
    "part_1 = pd.DataFrame(np.dot(model.factors.T, B_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "part_2 = pd.DataFrame(np.dot(Y_reg_train_std.T, C_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "Y_hat = (part_1 + part_2 + beta_const).T * Y_train_other.std()\n",
    "\n",
    "RMSE_insample = RMSE(Y_train_other, Y_hat)\n",
    "R2_insample = r2_score(Y_train_other, Y_hat)\n",
    "print(f'R2 insample: {R2_insample}')\n",
    "print(f'RMSE insample: {RMSE_insample}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 2: Dinsdag om 16.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after loading:\n",
      "                31/01/1995  28/02/1995  31/03/1995  30/04/1995  31/05/1995  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               30/06/1995  31/07/1995  31/08/1995  30/09/1995  31/10/1995  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  28/02/2023  31/03/2023  30/04/2023  31/05/2023  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               30/06/2023  31/07/2023  31/08/2023  30/09/2023  31/10/2023  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               30/11/2023  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data with datetime columns:\n",
      "                1995-01-31  1995-02-28  1995-03-31  1995-04-30  1995-05-31  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               1995-06-30  1995-07-31  1995-08-31  1995-09-30  1995-10-31  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  2023-02-28  2023-03-31  2023-04-30  2023-05-31  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               2023-06-30  2023-07-31  2023-08-31  2023-09-30  2023-10-31  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               2023-11-30  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data loaded with shape: (66, 347)\n",
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "Y_train_other shape: (54, 180)\n",
      "Y_reg_train shape: (66, 169)\n",
      "Y_train_other_std shape: (54, 180)\n",
      "Y_reg_train_std shape: (66, 169)\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "Shape of Y_train_other_std: (54, 180)\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shapes match, proceeding with dfm_fit_pcayw\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "Shape of X before any operation: (169, 66)\n",
      "Shape of Y before any operation: (180, 54)\n",
      "Shape mismatch in number of columns: adjusting Y\n",
      "New shape of Y after adjustment: (180, 54)\n",
      "Shape mismatch in number of rows: adjusting Y\n",
      "New shape of Y after adjustment: (169, 54)\n",
      "Transposed Shape of X: (66, 169)\n",
      "Transposed Shape of Y: (54, 169)\n",
      "R2 insample: 0.7950573540964421\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (169,66) and (54,66) not aligned: 66 (dim 1) != 54 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 176\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Corrected matrix dimensions for predictions\u001b[39;00m\n\u001b[0;32m    175\u001b[0m part_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mdot(model\u001b[38;5;241m.\u001b[39mfactors\u001b[38;5;241m.\u001b[39mT, B_matrix\u001b[38;5;241m.\u001b[39mT), columns\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m--> 176\u001b[0m part_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_reg_train_std\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m    177\u001b[0m Y_hat \u001b[38;5;241m=\u001b[39m (part_1 \u001b[38;5;241m+\u001b[39m part_2 \u001b[38;5;241m+\u001b[39m beta_const)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m Y_train_other\u001b[38;5;241m.\u001b[39mstd()\n\u001b[0;32m    179\u001b[0m RMSE_insample \u001b[38;5;241m=\u001b[39m RMSE(Y_train_other, Y_hat)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (169,66) and (54,66) not aligned: 66 (dim 1) != 54 (dim 0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import copy\n",
    "\n",
    "# Standaardisatie functie uit utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def read_and_preprocess_data(path):\n",
    "    data = pd.read_excel(path, engine='openpyxl', index_col=0)\n",
    "    print(\"Data after loading:\\n\", data.head())  # Print first few rows to inspect\n",
    "\n",
    "    data.columns = pd.to_datetime(data.columns, format='%d/%m/%Y')\n",
    "    print(\"Data with datetime columns:\\n\", data.head())  # Print first few rows to inspect\n",
    "    print(\"Data loaded with shape:\", data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNet()\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        # Transpose data_train_reg\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        # Debug statements to inspect shapes\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of columns\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of rows\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Transpose and convert X and Y to matrices\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        # Debug statements after transpose\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "FILE_PATH = r\"C:\\Thesis\\03. Data\\Final version data\\Static.xlsx\"\n",
    "df_data = read_and_preprocess_data(FILE_PATH)\n",
    "\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "print(\"Y_train_other shape:\", Y_train_other.shape)\n",
    "print(\"Y_reg_train shape:\", Y_reg_train.shape)\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "print(\"Y_reg_train_std shape:\", Y_reg_train_std.shape)\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Check lengths of the data to be passed to ElasticNet\n",
    "print(\"Shape of Y_train_other_std:\", Y_train_other_std.shape)\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "\n",
    "if Y_train_other_std.shape[0] == model.factors.T.shape[0]:\n",
    "    print(\"Shapes match, proceeding with dfm_fit_pcayw\")\n",
    "    B_matrix, C_matrix, r2_insample, beta_const = model.dfm_fit_pcayw(Y_train_other_std, Y_reg_train_std)\n",
    "    print(f'R2 insample: {r2_insample}')\n",
    "else:\n",
    "    print(\"Inconsistent lengths between Y_train_other_std en model.factors.T\")\n",
    "    print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "    print(\"model.factors.T shape:\", model.factors.T.shape)\n",
    "\n",
    "# Corrected matrix dimensions for predictions\n",
    "part_1 = pd.DataFrame(np.dot(model.factors.T, B_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "part_2 = pd.DataFrame(np.dot(Y_reg_train_std.T, C_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "Y_hat = (part_1 + part_2 + beta_const).T * Y_train_other.std()\n",
    "\n",
    "RMSE_insample = RMSE(Y_train_other, Y_hat)\n",
    "R2_insample = r2_score(Y_train_other, Y_hat)\n",
    "print(f'R2 insample: {R2_insample}')\n",
    "print(f'RMSE insample: {RMSE_insample}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 3: Dinsdag om 16.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after loading:\n",
      "                31/01/1995  28/02/1995  31/03/1995  30/04/1995  31/05/1995  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               30/06/1995  31/07/1995  31/08/1995  30/09/1995  31/10/1995  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  28/02/2023  31/03/2023  30/04/2023  31/05/2023  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               30/06/2023  31/07/2023  31/08/2023  30/09/2023  31/10/2023  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               30/11/2023  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data with datetime columns:\n",
      "                1995-01-31  1995-02-28  1995-03-31  1995-04-30  1995-05-31  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               1995-06-30  1995-07-31  1995-08-31  1995-09-30  1995-10-31  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  2023-02-28  2023-03-31  2023-04-30  2023-05-31  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               2023-06-30  2023-07-31  2023-08-31  2023-09-30  2023-10-31  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               2023-11-30  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data loaded with shape: (66, 347)\n",
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "Y_train_other shape: (54, 180)\n",
      "Y_reg_train shape: (66, 169)\n",
      "Y_train_other_std shape: (54, 180)\n",
      "Y_reg_train_std shape: (66, 169)\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "Shape of Y_train_other_std: (54, 180)\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shapes match, proceeding with dfm_fit_pcayw\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "Shape of X before any operation: (169, 66)\n",
      "Shape of Y before any operation: (180, 54)\n",
      "Shape mismatch in number of columns: adjusting Y\n",
      "New shape of Y after adjustment: (180, 54)\n",
      "Shape mismatch in number of rows: adjusting Y\n",
      "New shape of Y after adjustment: (169, 54)\n",
      "Transposed Shape of X: (66, 169)\n",
      "Transposed Shape of Y: (54, 169)\n",
      "R2 insample: 0.7950573540964421\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shape of B_matrix.T: (9, 180)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix.T: (54, 66)\n",
      "Shape of part_1: (54, 180)\n",
      "Shape of C_matrix_adjusted: (66, 54)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (169, 54), indices imply (54, 180)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 187\u001b[0m\n\u001b[0;32m    184\u001b[0m C_matrix_adjusted \u001b[38;5;241m=\u001b[39m C_matrix\u001b[38;5;241m.\u001b[39mT[:Y_reg_train_std\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], :Y_reg_train_std\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of C_matrix_adjusted:\u001b[39m\u001b[38;5;124m\"\u001b[39m, C_matrix_adjusted\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 187\u001b[0m part_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_reg_train_std\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_matrix_adjusted\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_train_other\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_train_other\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of part_2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, part_2\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    190\u001b[0m Y_hat \u001b[38;5;241m=\u001b[39m (part_1 \u001b[38;5;241m+\u001b[39m part_2 \u001b[38;5;241m+\u001b[39m beta_const)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m Y_train_other\u001b[38;5;241m.\u001b[39mstd()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (169, 54), indices imply (54, 180)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import copy\n",
    "\n",
    "# Standaardisatie functie uit utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def read_and_preprocess_data(path):\n",
    "    data = pd.read_excel(path, engine='openpyxl', index_col=0)\n",
    "    print(\"Data after loading:\\n\", data.head())  # Print first few rows to inspect\n",
    "\n",
    "    data.columns = pd.to_datetime(data.columns, format='%d/%m/%Y')\n",
    "    print(\"Data with datetime columns:\\n\", data.head())  # Print first few rows to inspect\n",
    "    print(\"Data loaded with shape:\", data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNet()\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        # Transpose data_train_reg\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        # Debug statements to inspect shapes\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of columns\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of rows\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Transpose and convert X and Y to matrices\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        # Debug statements after transpose\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "FILE_PATH = r\"C:\\Thesis\\03. Data\\Final version data\\Static.xlsx\"\n",
    "df_data = read_and_preprocess_data(FILE_PATH)\n",
    "\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "print(\"Y_train_other shape:\", Y_train_other.shape)\n",
    "print(\"Y_reg_train shape:\", Y_reg_train.shape)\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "print(\"Y_reg_train_std shape:\", Y_reg_train_std.shape)\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Check lengths of the data to be passed to ElasticNet\n",
    "print(\"Shape of Y_train_other_std:\", Y_train_other_std.shape)\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "\n",
    "if Y_train_other_std.shape[0] == model.factors.T.shape[0]:\n",
    "    print(\"Shapes match, proceeding with dfm_fit_pcayw\")\n",
    "    B_matrix, C_matrix, r2_insample, beta_const = model.dfm_fit_pcayw(Y_train_other_std, Y_reg_train_std)\n",
    "    print(f'R2 insample: {r2_insample}')\n",
    "else:\n",
    "    print(\"Inconsistent lengths between Y_train_other_std en model.factors.T\")\n",
    "    print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "    print(\"model.factors.T shape:\", model.factors.T.shape)\n",
    "\n",
    "# Corrected matrix dimensions for predictions\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "print(\"Shape of B_matrix.T:\", B_matrix.T.shape)\n",
    "print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "print(\"Shape of C_matrix.T:\", C_matrix.T.shape)\n",
    "\n",
    "part_1 = pd.DataFrame(np.dot(model.factors.T, B_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_1:\", part_1.shape)\n",
    "\n",
    "# Adjust the shape of C_matrix to match Y_reg_train_std\n",
    "C_matrix_adjusted = C_matrix.T[:Y_reg_train_std.shape[1], :Y_reg_train_std.shape[0]].T\n",
    "print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "\n",
    "part_2 = pd.DataFrame(np.dot(Y_reg_train_std.T, C_matrix_adjusted), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_2:\", part_2.shape)\n",
    "\n",
    "Y_hat = (part_1 + part_2 + beta_const).T * Y_train_other.std()\n",
    "\n",
    "RMSE_insample = RMSE(Y_train_other, Y_hat)\n",
    "R2_insample = r2_score(Y_train_other, Y_hat)\n",
    "print(f'R2 insample: {R2_insample}')\n",
    "print(f'RMSE insample: {RMSE_insample}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 4: Dinsdag om 16.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after loading:\n",
      "                31/01/1995  28/02/1995  31/03/1995  30/04/1995  31/05/1995  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               30/06/1995  31/07/1995  31/08/1995  30/09/1995  31/10/1995  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  28/02/2023  31/03/2023  30/04/2023  31/05/2023  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               30/06/2023  31/07/2023  31/08/2023  30/09/2023  31/10/2023  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               30/11/2023  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data with datetime columns:\n",
      "                1995-01-31  1995-02-28  1995-03-31  1995-04-30  1995-05-31  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               1995-06-30  1995-07-31  1995-08-31  1995-09-30  1995-10-31  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  2023-02-28  2023-03-31  2023-04-30  2023-05-31  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               2023-06-30  2023-07-31  2023-08-31  2023-09-30  2023-10-31  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               2023-11-30  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data loaded with shape: (66, 347)\n",
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "Y_train_other shape: (54, 180)\n",
      "Y_reg_train shape: (66, 169)\n",
      "Y_train_other_std shape: (54, 180)\n",
      "Y_reg_train_std shape: (66, 169)\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "Shape of Y_train_other_std: (54, 180)\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shapes match, proceeding with dfm_fit_pcayw\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "Shape of X before any operation: (169, 66)\n",
      "Shape of Y before any operation: (180, 54)\n",
      "Shape mismatch in number of columns: adjusting Y\n",
      "New shape of Y after adjustment: (180, 54)\n",
      "Shape mismatch in number of rows: adjusting Y\n",
      "New shape of Y after adjustment: (169, 54)\n",
      "Transposed Shape of X: (66, 169)\n",
      "Transposed Shape of Y: (54, 169)\n",
      "R2 insample: 0.7950573540964421\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shape of B_matrix.T: (9, 180)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix.T: (54, 66)\n",
      "Shape of part_1: (54, 180)\n",
      "Shape of C_matrix_adjusted: (54, 66)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (169,66) and (54,66) not aligned: 66 (dim 1) != 54 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 193\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of C_matrix_adjusted:\u001b[39m\u001b[38;5;124m\"\u001b[39m, C_matrix_adjusted\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch: Y_reg_train_std.T.shape[1] (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY_reg_train_std\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) != C_matrix_adjusted.shape[1] (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mC_matrix_adjusted\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 193\u001b[0m part_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_reg_train_std\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_matrix_adjusted\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of part_2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, part_2\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# Final prediction\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (169,66) and (54,66) not aligned: 66 (dim 1) != 54 (dim 0)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import copy\n",
    "\n",
    "# Standaardisatie functie uit utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def read_and_preprocess_data(path):\n",
    "    data = pd.read_excel(path, engine='openpyxl', index_col=0)\n",
    "    print(\"Data after loading:\\n\", data.head())  # Print first few rows to inspect\n",
    "\n",
    "    data.columns = pd.to_datetime(data.columns, format='%d/%m/%Y')\n",
    "    print(\"Data with datetime columns:\\n\", data.head())  # Print first few rows to inspect\n",
    "    print(\"Data loaded with shape:\", data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNet()\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        # Transpose data_train_reg\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        # Debug statements to inspect shapes\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of columns\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of rows\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Transpose and convert X and Y to matrices\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        # Debug statements after transpose\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "FILE_PATH = r\"C:\\Thesis\\03. Data\\Final version data\\Static.xlsx\"\n",
    "df_data = read_and_preprocess_data(FILE_PATH)\n",
    "\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "print(\"Y_train_other shape:\", Y_train_other.shape)\n",
    "print(\"Y_reg_train shape:\", Y_reg_train.shape)\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "print(\"Y_reg_train_std shape:\", Y_reg_train_std.shape)\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Check lengths of the data to be passed to ElasticNet\n",
    "print(\"Shape of Y_train_other_std:\", Y_train_other_std.shape)\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "\n",
    "if Y_train_other_std.shape[0] == model.factors.T.shape[0]:\n",
    "    print(\"Shapes match, proceeding with dfm_fit_pcayw\")\n",
    "    B_matrix, C_matrix, r2_insample, beta_const = model.dfm_fit_pcayw(Y_train_other_std, Y_reg_train_std)\n",
    "    print(f'R2 insample: {r2_insample}')\n",
    "else:\n",
    "    print(\"Inconsistent lengths between Y_train_other_std en model.factors.T\")\n",
    "    print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "    print(\"model.factors.T shape:\", model.factors.T.shape)\n",
    "\n",
    "# Corrected matrix dimensions for predictions\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "print(\"Shape of B_matrix.T:\", B_matrix.T.shape)\n",
    "print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "print(\"Shape of C_matrix.T:\", C_matrix.T.shape)\n",
    "\n",
    "part_1 = pd.DataFrame(np.dot(model.factors.T, B_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_1:\", part_1.shape)\n",
    "\n",
    "# Adjust the shape of C_matrix to match Y_reg_train_std\n",
    "C_matrix_adjusted = C_matrix.T[:Y_reg_train_std.shape[0], :]\n",
    "print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "\n",
    "# Perform matrix multiplication and ensure the dimensions match\n",
    "if Y_reg_train_std.T.shape[1] != C_matrix_adjusted.shape[1]:\n",
    "    print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "    print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "    raise ValueError(f\"Shape mismatch: Y_reg_train_std.T.shape[1] ({Y_reg_train_std.T.shape[1]}) != C_matrix_adjusted.shape[1] ({C_matrix_adjusted.shape[1]})\")\n",
    "\n",
    "part_2 = pd.DataFrame(np.dot(Y_reg_train_std.T, C_matrix_adjusted), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_2:\", part_2.shape)\n",
    "\n",
    "# Final prediction\n",
    "Y_hat = (part_1 + part_2 + beta_const).T * Y_train_other.std()\n",
    "\n",
    "RMSE_insample = RMSE(Y_train_other, Y_hat)\n",
    "R2_insample = r2_score(Y_train_other, Y_hat)\n",
    "print(f'R2 insample: {R2_insample}')\n",
    "print(f'RMSE insample: {RMSE_insample}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 5: Woensdag om 8.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after loading:\n",
      "                31/01/1995  28/02/1995  31/03/1995  30/04/1995  31/05/1995  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               30/06/1995  31/07/1995  31/08/1995  30/09/1995  31/10/1995  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  28/02/2023  31/03/2023  30/04/2023  31/05/2023  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               30/06/2023  31/07/2023  31/08/2023  30/09/2023  31/10/2023  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               30/11/2023  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data with datetime columns:\n",
      "                1995-01-31  1995-02-28  1995-03-31  1995-04-30  1995-05-31  \\\n",
      "CPI_Australia    0.024124    0.028044    0.031274    0.034579    0.036988   \n",
      "CPI_Canada       0.002320    0.013954    0.018562    0.020858    0.026637   \n",
      "CPI_Denmark      0.021439    0.018790    0.021865    0.020748    0.019117   \n",
      "CPI_Germany      0.019024    0.015133    0.018857    0.017588    0.016301   \n",
      "CPI_Japan        0.006263    0.006263   -0.002085   -0.005211   -0.003120   \n",
      "\n",
      "               1995-06-30  1995-07-31  1995-08-31  1995-09-30  1995-10-31  \\\n",
      "CPI_Australia    0.039623    0.042071    0.044041    0.046081    0.047395   \n",
      "CPI_Canada       0.026576    0.023069    0.024181    0.020738    0.024209   \n",
      "CPI_Denmark      0.022160    0.022717    0.014463    0.014960    0.018500   \n",
      "CPI_Germany      0.015038    0.013759    0.013725    0.016240    0.017500   \n",
      "CPI_Japan        0.003123    0.007311   -0.003133   -0.005211   -0.003110   \n",
      "\n",
      "               ...  2023-02-28  2023-03-31  2023-04-30  2023-05-31  \\\n",
      "CPI_Australia  ...    0.065820    0.063307    0.061996    0.058883   \n",
      "CPI_Canada     ...    0.047232    0.036920    0.036057    0.029194   \n",
      "CPI_Denmark    ...    0.063851    0.066867    0.048918    0.042560   \n",
      "CPI_Germany    ...    0.075388    0.063613    0.064941    0.060088   \n",
      "CPI_Japan      ...    0.038953    0.028281    0.028171    0.031902   \n",
      "\n",
      "               2023-06-30  2023-07-31  2023-08-31  2023-09-30  2023-10-31  \\\n",
      "CPI_Australia    0.055770    0.052499    0.050439    0.048379    0.046171   \n",
      "CPI_Canada       0.026462    0.026428    0.035407    0.038541    0.030101   \n",
      "CPI_Denmark      0.020907    0.012970    0.030851    0.011106   -0.001702   \n",
      "CPI_Germany      0.059231    0.057260    0.056204    0.041709    0.037185   \n",
      "CPI_Japan        0.031902    0.027954    0.028793    0.026796    0.023822   \n",
      "\n",
      "               2023-11-30  \n",
      "CPI_Australia    0.043963  \n",
      "CPI_Canada       0.029433  \n",
      "CPI_Denmark      0.009390  \n",
      "CPI_Germany      0.035424  \n",
      "CPI_Japan        0.030335  \n",
      "\n",
      "[5 rows x 347 columns]\n",
      "Data loaded with shape: (66, 347)\n",
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "Y_train_other shape: (54, 180)\n",
      "Y_reg_train shape: (66, 169)\n",
      "Y_train_other_std shape: (54, 180)\n",
      "Y_reg_train_std shape: (66, 169)\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "Shape of Y_train_other_std: (54, 180)\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shapes match, proceeding with dfm_fit_pcayw\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "Shape of X before any operation: (169, 66)\n",
      "Shape of Y before any operation: (180, 54)\n",
      "Shape mismatch in number of columns: adjusting Y\n",
      "New shape of Y after adjustment: (180, 54)\n",
      "Shape mismatch in number of rows: adjusting Y\n",
      "New shape of Y after adjustment: (169, 54)\n",
      "Transposed Shape of X: (66, 169)\n",
      "Transposed Shape of Y: (54, 169)\n",
      "R2 insample: 0.7950573540964421\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shape of B_matrix.T: (9, 180)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix.T: (54, 66)\n",
      "Shape of part_1: (54, 180)\n",
      "Shape of C_matrix_adjusted: (54, 66)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix_adjusted: (54, 66)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: Y_reg_train_std.T.shape[1] (66) != C_matrix_adjusted.shape[0] (54)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 193\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of Y_reg_train_std.T:\u001b[39m\u001b[38;5;124m\"\u001b[39m, Y_reg_train_std\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of C_matrix_adjusted:\u001b[39m\u001b[38;5;124m\"\u001b[39m, C_matrix_adjusted\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch: Y_reg_train_std.T.shape[1] (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY_reg_train_std\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) != C_matrix_adjusted.shape[0] (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mC_matrix_adjusted\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# Corrected matrix multiplication\u001b[39;00m\n\u001b[0;32m    196\u001b[0m part_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mdot(Y_reg_train_std\u001b[38;5;241m.\u001b[39mT, C_matrix_adjusted\u001b[38;5;241m.\u001b[39mT), columns\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mindex)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape mismatch: Y_reg_train_std.T.shape[1] (66) != C_matrix_adjusted.shape[0] (54)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import copy\n",
    "\n",
    "# Standaardisatie functie uit utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def read_and_preprocess_data(path):\n",
    "    data = pd.read_excel(path, engine='openpyxl', index_col=0)\n",
    "    print(\"Data after loading:\\n\", data.head())  # Print first few rows to inspect\n",
    "\n",
    "    data.columns = pd.to_datetime(data.columns, format='%d/%m/%Y')\n",
    "    print(\"Data with datetime columns:\\n\", data.head())  # Print first few rows to inspect\n",
    "    print(\"Data loaded with shape:\", data.shape)\n",
    "\n",
    "    return data\n",
    "\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNet()\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        # Transpose data_train_reg\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        # Debug statements to inspect shapes\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of columns\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of rows\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Transpose and convert X and Y to matrices\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        # Debug statements after transpose\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "FILE_PATH = r\"C:\\Thesis\\03. Data\\Final version data\\Static.xlsx\"\n",
    "df_data = read_and_preprocess_data(FILE_PATH)\n",
    "\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "print(\"Y_train_other shape:\", Y_train_other.shape)\n",
    "print(\"Y_reg_train shape:\", Y_reg_train.shape)\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "print(\"Y_reg_train_std shape:\", Y_reg_train_std.shape)\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Check lengths of the data to be passed to ElasticNet\n",
    "print(\"Shape of Y_train_other_std:\", Y_train_other_std.shape)\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "\n",
    "if Y_train_other_std.shape[0] == model.factors.T.shape[0]:\n",
    "    print(\"Shapes match, proceeding with dfm_fit_pcayw\")\n",
    "    B_matrix, C_matrix, r2_insample, beta_const = model.dfm_fit_pcayw(Y_train_other_std, Y_reg_train_std)\n",
    "    print(f'R2 insample: {r2_insample}')\n",
    "else:\n",
    "    print(\"Inconsistent lengths between Y_train_other_std en model.factors.T\")\n",
    "    print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "    print(\"model.factors.T shape:\", model.factors.T.shape)\n",
    "\n",
    "# Corrected matrix dimensions for predictions\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "print(\"Shape of B_matrix.T:\", B_matrix.T.shape)\n",
    "print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "print(\"Shape of C_matrix.T:\", C_matrix.T.shape)\n",
    "\n",
    "part_1 = pd.DataFrame(np.dot(model.factors.T, B_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_1:\", part_1.shape)\n",
    "\n",
    "# Correct the shape of C_matrix to match Y_reg_train_std\n",
    "C_matrix_adjusted = C_matrix.T[:Y_reg_train_std.shape[1], :]\n",
    "if C_matrix_adjusted.shape[1] != Y_reg_train_std.shape[1]:\n",
    "    C_matrix_adjusted = C_matrix_adjusted[:, :Y_reg_train_std.shape[1]]\n",
    "print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "\n",
    "# Perform matrix multiplication and ensure the dimensions match\n",
    "if Y_reg_train_std.T.shape[1] != C_matrix_adjusted.shape[0]:\n",
    "    print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "    print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "    raise ValueError(f\"Shape mismatch: Y_reg_train_std.T.shape[1] ({Y_reg_train_std.T.shape[1]}) != C_matrix_adjusted.shape[0] ({C_matrix_adjusted.shape[0]})\")\n",
    "\n",
    "# Corrected matrix multiplication\n",
    "part_2 = pd.DataFrame(np.dot(Y_reg_train_std.T, C_matrix_adjusted.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_2:\", part_2.shape)\n",
    "\n",
    "# Final prediction\n",
    "Y_hat = (part_1 + part_2 + beta_const).T * Y_train_other.std()\n",
    "\n",
    "RMSE_insample = RMSE(Y_train_other, Y_hat)\n",
    "R2_insample = r2_score(Y_train_other, Y_hat)\n",
    "print(f'R2 insample: {R2_insample}')\n",
    "print(f'RMSE insample: {RMSE_insample}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 6: Woensdag om 9.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "Shape of Y_train_other_std: (54, 180)\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shapes match, proceeding with dfm_fit_pcayw\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "Shape of X before any operation: (169, 66)\n",
      "Shape of Y before any operation: (180, 54)\n",
      "Shape mismatch in number of columns: adjusting Y\n",
      "New shape of Y after adjustment: (180, 54)\n",
      "Shape mismatch in number of rows: adjusting Y\n",
      "New shape of Y after adjustment: (169, 54)\n",
      "Transposed Shape of X: (66, 169)\n",
      "Transposed Shape of Y: (54, 169)\n",
      "R2 insample: 0.7950573540964421\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shape of B_matrix.T: (9, 180)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix.T: (54, 66)\n",
      "Shape of part_1: (54, 180)\n",
      "Shape of C_matrix_adjusted: (54, 66)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix_adjusted: (54, 66)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch: Y_reg_train_std.T.shape[1] (66) != C_matrix_adjusted.shape[0] (54)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 175\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of Y_reg_train_std.T:\u001b[39m\u001b[38;5;124m\"\u001b[39m, Y_reg_train_std\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of C_matrix_adjusted:\u001b[39m\u001b[38;5;124m\"\u001b[39m, C_matrix_adjusted\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch: Y_reg_train_std.T.shape[1] (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY_reg_train_std\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) != C_matrix_adjusted.shape[0] (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mC_matrix_adjusted\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    177\u001b[0m part_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39mdot(Y_reg_train_std\u001b[38;5;241m.\u001b[39mT, C_matrix_adjusted), columns\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of part_2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, part_2\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape mismatch: Y_reg_train_std.T.shape[1] (66) != C_matrix_adjusted.shape[0] (54)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Utilities from utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(data: pd.DataFrame, estimation: pd.DataFrame):\n",
    "    df_errors = (estimation - data)\n",
    "    df_rmse = ((df_errors) ** 2.0).mean(axis=0) ** 0.5\n",
    "    return df_rmse\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNet()\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        # Transpose data_train_reg\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        # Debug statements to inspect shapes\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of columns\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Ensure X and Y have the same number of rows\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        # Transpose and convert X and Y to matrices\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        # Debug statements after transpose\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "FILE_PATH = r\"C:\\Thesis\\03. Data\\Final version data\\Static.xlsx\"\n",
    "df_data = pd.read_excel(FILE_PATH, engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y')\n",
    "\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Check lengths of the data to be passed to ElasticNet\n",
    "print(\"Shape of Y_train_other_std:\", Y_train_other_std.shape)\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "\n",
    "if Y_train_other_std.shape[0] == model.factors.T.shape[0]:\n",
    "    print(\"Shapes match, proceeding with dfm_fit_pcayw\")\n",
    "    B_matrix, C_matrix, r2_insample, beta_const = model.dfm_fit_pcayw(Y_train_other_std, Y_reg_train_std)\n",
    "    print(f'R2 insample: {r2_insample}')\n",
    "else:\n",
    "    print(\"Inconsistent lengths between Y_train_other_std en model.factors.T\")\n",
    "    print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "    print(\"model.factors.T shape:\", model.factors.T.shape)\n",
    "\n",
    "# Corrected matrix dimensions for predictions\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "print(\"Shape of B_matrix.T:\", B_matrix.T.shape)\n",
    "print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "print(\"Shape of C_matrix.T:\", C_matrix.T.shape)\n",
    "\n",
    "part_1 = pd.DataFrame(np.dot(model.factors.T, B_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_1:\", part_1.shape)\n",
    "\n",
    "# Adjust the shape of C_matrix to match Y_reg_train_std\n",
    "C_matrix_adjusted = C_matrix.T\n",
    "print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "\n",
    "# Perform matrix multiplication and ensure the dimensions match\n",
    "if Y_reg_train_std.T.shape[1] != C_matrix_adjusted.shape[0]:\n",
    "    print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "    print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "    raise ValueError(f\"Shape mismatch: Y_reg_train_std.T.shape[1] ({Y_reg_train_std.T.shape[1]}) != C_matrix_adjusted.shape[0] ({C_matrix_adjusted.shape[0]})\")\n",
    "\n",
    "part_2 = pd.DataFrame(np.dot(Y_reg_train_std.T, C_matrix_adjusted), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_2:\", part_2.shape)\n",
    "\n",
    "# Final prediction\n",
    "Y_hat = (part_1 + part_2 + beta_const).T * Y_train_other.std()\n",
    "\n",
    "RMSE_insample = RMSE(Y_train_other, Y_hat)\n",
    "R2_insample = r2_score(Y_train_other, Y_hat)\n",
    "print(f'R2 insample: {R2_insample}')\n",
    "print(f'RMSE insample: {RMSE_insample}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 7: Woensdag om 9.58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "Shape of Y_train_other_std: (54, 180)\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shapes match, proceeding with dfm_fit_pcayw\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "Shape of X before any operation: (169, 66)\n",
      "Shape of Y before any operation: (180, 54)\n",
      "Shape mismatch in number of columns: adjusting Y\n",
      "New shape of Y after adjustment: (180, 54)\n",
      "Shape mismatch in number of rows: adjusting Y\n",
      "New shape of Y after adjustment: (169, 54)\n",
      "Transposed Shape of X: (66, 169)\n",
      "Transposed Shape of Y: (54, 169)\n",
      "R2 insample: 0.7950573540964421\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shape of B_matrix.T: (9, 180)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix.T: (54, 66)\n",
      "Shape of part_1: (54, 180)\n",
      "Shape of C_matrix_adjusted: (54, 66)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix_adjusted: (54, 66)\n",
      "Adjusted shape of C_matrix_adjusted: (66, 66)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (169, 66), indices imply (54, 180)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 169\u001b[0m\n\u001b[0;32m    166\u001b[0m         C_matrix_adjusted \u001b[38;5;241m=\u001b[39m C_matrix_adjusted[:Y_reg_train_std\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], :]\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdjusted shape of C_matrix_adjusted:\u001b[39m\u001b[38;5;124m\"\u001b[39m, C_matrix_adjusted\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 169\u001b[0m part_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_reg_train_std\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC_matrix_adjusted\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_train_other\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_train_other\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of part_2:\u001b[39m\u001b[38;5;124m\"\u001b[39m, part_2\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    172\u001b[0m Y_hat \u001b[38;5;241m=\u001b[39m (part_1 \u001b[38;5;241m+\u001b[39m part_2 \u001b[38;5;241m+\u001b[39m beta_const)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m*\u001b[39m Y_train_other\u001b[38;5;241m.\u001b[39mstd()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[0;32m    825\u001b[0m         )\n\u001b[0;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    334\u001b[0m )\n\u001b[1;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (169, 66), indices imply (54, 180)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Utilities from utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(data: pd.DataFrame, estimation: pd.DataFrame):\n",
    "    df_errors = (estimation - data)\n",
    "    df_rmse = ((df_errors) ** 2.0).mean(axis=0) ** 0.5\n",
    "    return df_rmse\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNet()\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "df_data = pd.read_excel(\"C:/Thesis/03. Data/Final version data/Static.xlsx\", engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y')\n",
    "\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "model.std_data = Y_train_other_std.T\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "print(\"Shape of Y_train_other_std:\", Y_train_other_std.shape)\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "\n",
    "if Y_train_other_std.shape[0] == model.factors.T.shape[0]:\n",
    "    print(\"Shapes match, proceeding with dfm_fit_pcayw\")\n",
    "    B_matrix, C_matrix, r2_insample, beta_const = model.dfm_fit_pcayw(Y_train_other_std, Y_reg_train_std)\n",
    "    print(f'R2 insample: {r2_insample}')\n",
    "else:\n",
    "    print(\"Inconsistent lengths between Y_train_other_std en model.factors.T\")\n",
    "    print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "    print(\"model.factors.T shape:\", model.factors.T.shape)\n",
    "\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "print(\"Shape of B_matrix.T:\", B_matrix.T.shape)\n",
    "print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "print(\"Shape of C_matrix.T:\", C_matrix.T.shape)\n",
    "\n",
    "part_1 = pd.DataFrame(np.dot(model.factors.T, B_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_1:\", part_1.shape)\n",
    "\n",
    "C_matrix_adjusted = C_matrix.T\n",
    "print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "\n",
    "if Y_reg_train_std.T.shape[1] != C_matrix_adjusted.shape[0]:\n",
    "    print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "    print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "    if Y_reg_train_std.T.shape[1] > C_matrix_adjusted.shape[0]:\n",
    "        C_matrix_adjusted = np.pad(C_matrix_adjusted, ((0, Y_reg_train_std.T.shape[1] - C_matrix_adjusted.shape[0]), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        C_matrix_adjusted = C_matrix_adjusted[:Y_reg_train_std.T.shape[1], :]\n",
    "    print(\"Adjusted shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "\n",
    "part_2 = pd.DataFrame(np.dot(Y_reg_train_std.T, C_matrix_adjusted), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_2:\", part_2.shape)\n",
    "\n",
    "Y_hat = (part_1 + part_2 + beta_const).T * Y_train_other.std()\n",
    "\n",
    "RMSE_insample = RMSE(Y_train_other, Y_hat)\n",
    "R2_insample = r2_score(Y_train_other, Y_hat)\n",
    "print(f'R2 insample: {R2_insample}')\n",
    "print(f'RMSE insample: {RMSE_insample}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 8: Woensdag om 10.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "Shape of Y_train_other_std: (54, 180)\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shapes match, proceeding with dfm_fit_pcayw\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "Shape of X before any operation: (169, 66)\n",
      "Shape of Y before any operation: (180, 54)\n",
      "Shape mismatch in number of columns: adjusting Y\n",
      "New shape of Y after adjustment: (180, 54)\n",
      "Shape mismatch in number of rows: adjusting Y\n",
      "New shape of Y after adjustment: (169, 54)\n",
      "Transposed Shape of X: (66, 169)\n",
      "Transposed Shape of Y: (54, 169)\n",
      "R2 insample: 0.7950573540964421\n",
      "Shape of model.factors.T: (54, 9)\n",
      "Shape of B_matrix.T: (9, 180)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix.T: (54, 66)\n",
      "Shape of part_1: (54, 180)\n",
      "Shape of C_matrix_adjusted: (54, 66)\n",
      "Shape of Y_reg_train_std.T: (169, 66)\n",
      "Shape of C_matrix_adjusted: (54, 66)\n",
      "Adjusted shape of C_matrix_adjusted: (66, 66)\n",
      "Shape of part_2: (169, 66)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (169,66) into shape (54,66)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 175\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Zorg ervoor dat de dimensies van part_2 overeenkomen met die van part_1\u001b[39;00m\n\u001b[0;32m    174\u001b[0m part_2_corrected \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(part_1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 175\u001b[0m \u001b[43mpart_2_corrected\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mpart_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mpart_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m part_2\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrected shape of part_2 to match part_1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, part_2_corrected\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    178\u001b[0m part_2_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(part_2_corrected, columns\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mcolumns, index\u001b[38;5;241m=\u001b[39mY_train_other\u001b[38;5;241m.\u001b[39mindex)\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (169,66) into shape (54,66)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Utilities from utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(data: pd.DataFrame, estimation: pd.DataFrame):\n",
    "    df_errors = (estimation - data)\n",
    "    df_rmse = ((df_errors) ** 2.0).mean(axis=0) ** 0.5\n",
    "    return df_rmse\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNet()\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "df_data = pd.read_excel(\"C:/Thesis/03. Data/Final version data/Static.xlsx\", engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y')\n",
    "\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "model.std_data = Y_train_other_std.T\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "print(\"Shape of Y_train_other_std:\", Y_train_other_std.shape)\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "\n",
    "if Y_train_other_std.shape[0] == model.factors.T.shape[0]:\n",
    "    print(\"Shapes match, proceeding with dfm_fit_pcayw\")\n",
    "    B_matrix, C_matrix, r2_insample, beta_const = model.dfm_fit_pcayw(Y_train_other_std, Y_reg_train_std)\n",
    "    print(f'R2 insample: {r2_insample}')\n",
    "else:\n",
    "    print(\"Inconsistent lengths between Y_train_other_std en model.factors.T\")\n",
    "    print(\"Y_train_other_std shape:\", Y_train_other_std.shape)\n",
    "    print(\"model.factors.T shape:\", model.factors.T.shape)\n",
    "\n",
    "print(\"Shape of model.factors.T:\", model.factors.T.shape)\n",
    "print(\"Shape of B_matrix.T:\", B_matrix.T.shape)\n",
    "print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "print(\"Shape of C_matrix.T:\", C_matrix.T.shape)\n",
    "\n",
    "part_1 = pd.DataFrame(np.dot(model.factors.T, B_matrix.T), columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "print(\"Shape of part_1:\", part_1.shape)\n",
    "\n",
    "C_matrix_adjusted = C_matrix.T\n",
    "print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "\n",
    "# Controleer en pas de vorm van C_matrix_adjusted aan\n",
    "if Y_reg_train_std.T.shape[1] != C_matrix_adjusted.shape[0]:\n",
    "    print(\"Shape of Y_reg_train_std.T:\", Y_reg_train_std.T.shape)\n",
    "    print(\"Shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "    if Y_reg_train_std.T.shape[1] > C_matrix_adjusted.shape[0]:\n",
    "        C_matrix_adjusted = np.pad(C_matrix_adjusted, ((0, Y_reg_train_std.T.shape[1] - C_matrix_adjusted.shape[0]), (0, 0)), mode='constant')\n",
    "    else:\n",
    "        C_matrix_adjusted = C_matrix_adjusted[:Y_reg_train_std.T.shape[1], :]\n",
    "    print(\"Adjusted shape of C_matrix_adjusted:\", C_matrix_adjusted.shape)\n",
    "\n",
    "part_2 = np.dot(Y_reg_train_std.T, C_matrix_adjusted)\n",
    "print(\"Shape of part_2:\", part_2.shape)\n",
    "\n",
    "# Zorg ervoor dat de dimensies van part_2 overeenkomen met die van part_1\n",
    "part_2_corrected = np.zeros(part_1.shape)\n",
    "part_2_corrected[:part_2.shape[0], :part_2.shape[1]] = part_2\n",
    "print(\"Corrected shape of part_2 to match part_1:\", part_2_corrected.shape)\n",
    "\n",
    "part_2_df = pd.DataFrame(part_2_corrected, columns=Y_train_other.columns, index=Y_train_other.index)\n",
    "\n",
    "Y_hat = (part_1 + part_2_df + beta_const).T * Y_train_other.std()\n",
    "\n",
    "RMSE_insample = RMSE(Y_train_other, Y_hat)\n",
    "R2_insample = r2_score(Y_train_other, Y_hat)\n",
    "print(f'R2 insample: {R2_insample}')\n",
    "print(f'RMSE insample: {RMSE_insample}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 9: Woensdag om 10.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((9, 54),\n",
       " (10, 9),\n",
       " (180, 9),\n",
       " 0.8101878205359425,\n",
       " array([ 6.16924340e-02,  1.07507116e-01,  9.79443126e-02,  3.30364741e-01,\n",
       "         2.62076946e-01,  1.89734928e-01,  3.55808077e-01,  2.03677267e-01,\n",
       "         2.06333920e-01,  8.17962458e-02,  2.19041426e-01,  2.19959004e-01,\n",
       "         2.75621744e-01,  2.50410153e-01,  2.64088179e-01,  2.63923713e-01,\n",
       "         1.76431327e-01,  1.98066788e-01,  2.39612888e-02,  2.41615034e-01,\n",
       "         2.40083071e-01,  1.61604138e-01,  3.30754782e-01,  1.52347774e-01,\n",
       "         3.17372492e-01,  1.75737334e-01,  1.43760085e-01,  2.10404686e-01,\n",
       "         3.07112363e-01,  3.79767971e-01,  4.90975748e-01, -2.48195375e-02,\n",
       "         3.74184639e-01, -1.10177085e-01,  1.00443005e-01,  1.51867037e-01,\n",
       "         1.15420078e-01,  2.27384030e-01,  2.94050963e-01,  5.36900860e-02,\n",
       "         1.07834058e-02, -5.58390646e-02, -9.22229370e-02, -7.44133476e-01,\n",
       "        -4.12030299e-01,  8.70227358e-02,  7.43527117e-02, -2.04459360e-02,\n",
       "         4.88388581e-03, -1.58645636e-01,  2.56167201e-02,  1.69409067e-01,\n",
       "        -2.18147302e-01,  1.17702417e-01, -1.31877864e-02,  2.85986054e-02,\n",
       "         7.09831294e-02,  2.38925414e-01,  2.83576500e-01,  4.60694138e-01,\n",
       "        -4.31843800e-02,  2.37394764e-01,  2.23500460e-01, -1.75323122e-02,\n",
       "         8.32785175e-02,  1.56251563e-01,  1.21308893e-01,  2.58101019e-01,\n",
       "        -8.57034108e-02,  3.20809124e-02, -2.14616921e-01, -1.14410389e-01,\n",
       "         1.17403756e-01, -3.22551574e-01, -3.02926711e-01,  2.28028339e-01,\n",
       "         1.55801748e-02, -1.32711126e-01, -1.34170661e-01, -3.12442565e-01,\n",
       "        -5.45543335e-01, -4.21385037e-03,  1.90348150e-01,  7.49779407e-02,\n",
       "        -1.25077522e-01, -1.61091817e-02,  1.39729250e-01, -2.41295393e-01,\n",
       "        -1.08234259e-01, -3.95852248e-01, -5.13568724e-01, -1.07500488e-01,\n",
       "        -5.58047417e-01,  1.39088036e-01,  6.46285397e-02, -4.54344441e-01,\n",
       "        -3.70683830e-01, -3.43154302e-01, -2.23252924e-01,  2.22321929e-01,\n",
       "        -1.01496685e-01, -7.52193110e-04,  9.64532180e-02,  6.21901043e-02,\n",
       "        -1.49857621e-01,  2.27616355e-01, -1.59587748e-02,  1.78577747e-01,\n",
       "         1.68484909e-01,  2.19722242e-01,  3.76341320e-02,  1.05424505e-01,\n",
       "         7.83969821e-02,  2.19128967e-01,  1.83927403e-02,  3.77274063e-02,\n",
       "         1.65078015e-01,  2.27600862e-02,  2.11545325e-01,  1.34129437e-01,\n",
       "         4.57916373e-02,  2.16699922e-01,  1.55710019e-03, -1.16727536e-01,\n",
       "         1.65197661e-01,  1.41649461e-01,  2.01245129e-01,  8.84233505e-02,\n",
       "         2.42728420e-01, -5.75155326e-02,  1.73105864e-01,  1.46786970e-01,\n",
       "         1.35828293e-01,  1.65976423e-02,  2.42490349e-01,  1.68123659e-01,\n",
       "        -1.46315388e-01,  3.54529258e-02,  1.07927715e-02,  6.67160632e-02,\n",
       "        -1.81278502e-02,  1.37144315e-01,  3.16825113e-02,  1.87130212e-01,\n",
       "         1.22308995e-01, -3.19315003e-02,  8.24273494e-02,  1.23529538e-01,\n",
       "         1.86331187e-01,  4.74315884e-02, -2.18969036e-02,  4.23539261e-03,\n",
       "         1.70967437e-01,  1.15121667e-01, -1.68945384e-01, -6.86730730e-02,\n",
       "        -5.85205724e-01, -1.39748422e-01, -3.52253481e-01,  9.07017640e-03,\n",
       "        -1.19304762e-01, -5.93708091e-01, -4.14985282e-01, -3.19894810e-01,\n",
       "        -1.00904974e+00, -1.25064149e+00, -9.07182083e-01, -7.32366454e-01,\n",
       "        -8.51911833e-01, -1.00254203e+00, -5.47794896e-01, -2.35894624e-01,\n",
       "        -4.48747360e-01, -5.91916950e-01, -2.05297770e-01, -3.51165117e-01,\n",
       "        -2.48039714e-01, -2.67417893e-01, -7.65991501e-02,  9.98358173e-02]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Utilities from utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(data: pd.DataFrame, estimation: pd.DataFrame):\n",
    "    df_errors = (estimation - data)\n",
    "    df_rmse = ((df_errors) ** 2.0).mean(axis=0) ** 0.5\n",
    "    return df_rmse\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNet()\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "df_data = pd.read_excel(\"C:/Thesis/03. Data/Final version data/Static.xlsx\", engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y')\n",
    "\n",
    "# Initialize the model\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "# Check the attributes of the model to ensure correct initialization\n",
    "std_data_shape = model.std_data.shape\n",
    "pca_initialized = isinstance(model.pca, PCA)\n",
    "factors_initialized = model.factors is None\n",
    "phi_initialized = model.phi is None\n",
    "B_mat_initialized = model.B_mat is None\n",
    "\n",
    "std_data_shape, pca_initialized, factors_initialized, phi_initialized, B_mat_initialized\n",
    "\n",
    "# Define the validation date and split the data\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "# Check the prepared datasets\n",
    "(Y_train_PCA.shape, Y_train_other.shape, Y_reg_train.shape, \n",
    " Y_train_other_std.shape, Y_reg_train_std.shape)\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Check the results after applying PCA and Yule-Walker estimation\n",
    "pca_factors_shape = model.factors.shape\n",
    "yw_estimation_shape = model.phi.shape\n",
    "\n",
    "# Fit the ElasticNet model\n",
    "# For this, we need some training data. Let's use the first part of the standardized data as a placeholder.\n",
    "data_train = model.std_data[:, :int(model.std_data.shape[1] * 0.8)].T\n",
    "fac_train = model.factors.T[:int(model.factors.shape[1] * 0.8), :]\n",
    "\n",
    "B_matrix, r2_insample, intercept = model.enet_fit(data_train, fac_train)\n",
    "\n",
    "# Check the results after fitting ElasticNet\n",
    "B_matrix_shape = B_matrix.shape\n",
    "r2_insample_value = r2_insample\n",
    "intercept_value = intercept\n",
    "\n",
    "(pca_factors_shape, yw_estimation_shape, B_matrix_shape, r2_insample_value, intercept_value)\n",
    "\n",
    "## Validation Data\n",
    "#data_validate = model.std_data[:, int(model.std_data.shape[1] * 0.8):].T\n",
    "#fac_validate = model.factors.T[int(model.factors.shape[1] * 0.8):, :]\n",
    "\n",
    "# Predict using the model\n",
    "#y_hat_validate = model.enet_predict(fac_validate)\n",
    "\n",
    "# Compute RMSE for validation data\n",
    "#rmse_value = RMSE(data_validate, y_hat_validate)\n",
    "\n",
    "# Check RMSE value\n",
    "#rmse_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 10: Woensdag om 11.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [54, 180]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m data_train \u001b[38;5;241m=\u001b[39m Y_train_other_std\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     87\u001b[0m fac_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfactors\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m---> 89\u001b[0m B_matrix, r2_insample, intercept \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menet_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfac_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# Check the results after fitting ElasticNet with cross-validation\u001b[39;00m\n\u001b[0;32m     92\u001b[0m B_matrix_shape \u001b[38;5;241m=\u001b[39m B_matrix\u001b[38;5;241m.\u001b[39mshape\n",
      "Cell \u001b[1;32mIn[46], line 39\u001b[0m, in \u001b[0;36mDynamicFactorModel.enet_fit\u001b[1;34m(self, data_train, fac_train)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menet_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_train, fac_train):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_ena \u001b[38;5;241m=\u001b[39m ElasticNetCV(cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_ena\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfac_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB_mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_ena\u001b[38;5;241m.\u001b[39mcoef_\n\u001b[0;32m     41\u001b[0m     x_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_ena\u001b[38;5;241m.\u001b[39mpredict(fac_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1616\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[1;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[0;32m   1611\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1612\u001b[0m         X, y, validate_separately\u001b[38;5;241m=\u001b[39m(check_X_params, check_y_params)\n\u001b[0;32m   1613\u001b[0m     )\n\u001b[0;32m   1614\u001b[0m     copy_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1616\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multitask():\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [54, 180]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Define standardize function\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "# Define the DynamicFactorModel class\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = ElasticNetCV(cv=5)\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "# Load and preprocess data\n",
    "file_path = \"C:/Thesis/03. Data/Final version data/Static.xlsx\"\n",
    "df_data = pd.read_excel(file_path, engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y')\n",
    "\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "# Define the validation date and split the data\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "# Check the prepared datasets\n",
    "(Y_train_PCA.shape, Y_train_other.shape, Y_reg_train.shape, \n",
    " Y_train_other_std.shape, Y_reg_train_std.shape)\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Fit the ElasticNet model with cross-validation\n",
    "data_train = Y_train_other_std.T\n",
    "fac_train = model.factors.T\n",
    "\n",
    "B_matrix, r2_insample, intercept = model.enet_fit(data_train, fac_train)\n",
    "\n",
    "# Check the results after fitting ElasticNet with cross-validation\n",
    "B_matrix_shape = B_matrix.shape\n",
    "r2_insample_value = r2_insample\n",
    "intercept_value = intercept\n",
    "\n",
    "(pca_factors_shape, yw_estimation_shape, B_matrix_shape, r2_insample_value, intercept_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 11: Woensdag om 11:28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01-31 00:00:00\n",
      "((66, 180), (54, 180), (66, 169), (54, 180), (66, 169))\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "RMSE: [0.34540093 0.25503345 0.30784261 0.30565958 0.23967187 0.30148706\n",
      " 0.2574635  0.23799561 0.24229224 0.21184805 0.2395499  0.25038898\n",
      " 0.20970424 0.22180457 0.15270446 0.21198822 0.20914793 0.14661331\n",
      " 0.16021209 0.14500789 0.20079238 0.16623088 0.17889684 0.16676639\n",
      " 0.15696864 0.19615548 0.20479252 0.24594497 0.20859949 0.17645157\n",
      " 0.14118905 0.25968953 0.16137724 0.21210136 0.13436814 0.15384759\n",
      " 0.17726176 0.18577161 0.23552222 0.23003837 0.13582258 0.17038916\n",
      " 0.15141175 0.20457154 0.2021699  0.25285294 0.27132298 0.27583883\n",
      " 0.22778871 0.2489437  0.17845143 0.20094289 0.21110068 0.1938872\n",
      " 0.23349201 0.29098672 0.22088326 0.21526476 0.18435644 0.15868665\n",
      " 0.20141707 0.15246414 0.20647296 0.13419565 0.14623452 0.13790227\n",
      " 0.15323414 0.1302494  0.17851331 0.19124412 0.15696224 0.09614018\n",
      " 0.17442745 0.19530938 0.18804463 0.24807925 0.22116813 0.22260066\n",
      " 0.21105695 0.19791918 0.15019742 0.23017892 0.25833022 0.22857165\n",
      " 0.23443901 0.23150501 0.24706304 0.18867818 0.18328172 0.16417723\n",
      " 0.12406814 0.2387401  0.19662601 0.30288398 0.22541077 0.1503673\n",
      " 0.15389637 0.18505125 0.18996455 0.24602198 0.19778565 0.15974929\n",
      " 0.11272114 0.13663689 0.13123504 0.17899246 0.15488258 0.1598909\n",
      " 0.15767774 0.16297806 0.18181297 0.25482374 0.29359975 0.30059507\n",
      " 0.2174752  0.21379172 0.18101924 0.18764505 0.12258891 0.16689757\n",
      " 0.12116896 0.12409925 0.15435959 0.15650704 0.14827317 0.15619245\n",
      " 0.1451166  0.14913978 0.16270063 0.17471741 0.20071137 0.16605472\n",
      " 0.17941506 0.16801947 0.13371301 0.11623247 0.15285757 0.18039311\n",
      " 0.19194701 0.15810691 0.15770749 0.14934526 0.1616777  0.17658674\n",
      " 0.20489205 0.21232063 0.26093249 0.26004309 0.20146081 0.24846473\n",
      " 0.2849262  0.22785772 0.19972113 0.17469119 0.19865496 0.18925713\n",
      " 0.25045102 0.28154379 0.28894775 0.30908264 0.27206122 0.2455171\n",
      " 0.26183551 0.34511544 0.29299214 0.26944887 0.2140796  0.2659796\n",
      " 0.13593848 0.21183082 0.1809959  0.10004435 0.19033915 0.16070894\n",
      " 0.07303468 0.08965014 0.08143961 0.12012099 0.12410733 0.21655626]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Utilities from utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(data: pd.DataFrame, estimation: pd.DataFrame):\n",
    "    df_errors = (estimation - data)\n",
    "    df_rmse = ((df_errors) ** 2.0).mean(axis=0) ** 0.5\n",
    "    return df_rmse\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = MultiTaskElasticNetCV(cv=5)\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "df_data = pd.read_excel(\"C:/Thesis/03. Data/Final version data/Static.xlsx\", engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y')\n",
    "\n",
    "# Initialize the model\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "# Define the validation date and split the data\n",
    "DATE_VALIDATE = datetime.strptime('31/01/2010', '%d/%m/%Y')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "# Check the prepared datasets\n",
    "print((Y_train_PCA.shape, Y_train_other.shape, Y_reg_train.shape, \n",
    " Y_train_other_std.shape, Y_reg_train_std.shape))\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Check the results after applying PCA and Yule-Walker estimation\n",
    "pca_factors_shape = model.factors.shape\n",
    "yw_estimation_shape = model.phi.shape\n",
    "\n",
    "# Fit the ElasticNet model with cross-validation\n",
    "data_train = model.std_data[:, :int(model.std_data.shape[1] * 0.8)].T\n",
    "fac_train = model.factors.T[:int(model.factors.shape[1] * 0.8), :]\n",
    "\n",
    "B_matrix, r2_insample, intercept = model.enet_fit(data_train, fac_train)\n",
    "\n",
    "# Check the results after fitting ElasticNet with cross-validation\n",
    "B_matrix_shape = B_matrix.shape\n",
    "r2_insample_value = r2_insample\n",
    "intercept_value = intercept\n",
    "\n",
    "(pca_factors_shape, yw_estimation_shape, B_matrix_shape, r2_insample_value, intercept_value)\n",
    "\n",
    "# Validation Data\n",
    "data_validate = model.std_data[:, int(model.std_data.shape[1] * 0.8):].T\n",
    "fac_validate = model.factors.T[int(model.factors.shape[1] * 0.8):, :]\n",
    "\n",
    "# Predict using the model\n",
    "y_hat_validate = model.enet_predict(fac_validate)\n",
    "\n",
    "# Compute RMSE for validation data\n",
    "rmse_value = RMSE(data_validate, y_hat_validate)\n",
    "\n",
    "# Check RMSE value\n",
    "print(f\"RMSE: {rmse_value}\")\n",
    "\n",
    "# RMSE waarden plotten\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(rmse_value)), rmse_value)\n",
    "plt.xlabel('Variable Index')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for Each Variable in the Validation Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 12: Woensdag 13:13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data shape: (66, 347)\n",
      "DATE_VALIDATE: 2010-01\n",
      "((66, 180), (54, 180), (66, 169), (54, 180), (66, 169))\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (180, 9)\n",
      "RMSE: [0.34540093 0.25503345 0.30784261 0.30565958 0.23967187 0.30148706\n",
      " 0.2574635  0.23799561 0.24229224 0.21184805 0.2395499  0.25038898\n",
      " 0.20970424 0.22180457 0.15270446 0.21198822 0.20914793 0.14661331\n",
      " 0.16021209 0.14500789 0.20079238 0.16623088 0.17889684 0.16676639\n",
      " 0.15696864 0.19615548 0.20479252 0.24594497 0.20859949 0.17645157\n",
      " 0.14118905 0.25968953 0.16137724 0.21210136 0.13436814 0.15384759\n",
      " 0.17726176 0.18577161 0.23552222 0.23003837 0.13582258 0.17038916\n",
      " 0.15141175 0.20457154 0.2021699  0.25285294 0.27132298 0.27583883\n",
      " 0.22778871 0.2489437  0.17845143 0.20094289 0.21110068 0.1938872\n",
      " 0.23349201 0.29098672 0.22088326 0.21526476 0.18435644 0.15868665\n",
      " 0.20141707 0.15246414 0.20647296 0.13419565 0.14623452 0.13790227\n",
      " 0.15323414 0.1302494  0.17851331 0.19124412 0.15696224 0.09614018\n",
      " 0.17442745 0.19530938 0.18804463 0.24807925 0.22116813 0.22260066\n",
      " 0.21105695 0.19791918 0.15019742 0.23017892 0.25833022 0.22857165\n",
      " 0.23443901 0.23150501 0.24706304 0.18867818 0.18328172 0.16417723\n",
      " 0.12406814 0.2387401  0.19662601 0.30288398 0.22541077 0.1503673\n",
      " 0.15389637 0.18505125 0.18996455 0.24602198 0.19778565 0.15974929\n",
      " 0.11272114 0.13663689 0.13123504 0.17899246 0.15488258 0.1598909\n",
      " 0.15767774 0.16297806 0.18181297 0.25482374 0.29359975 0.30059507\n",
      " 0.2174752  0.21379172 0.18101924 0.18764505 0.12258891 0.16689757\n",
      " 0.12116896 0.12409925 0.15435959 0.15650704 0.14827317 0.15619245\n",
      " 0.1451166  0.14913978 0.16270063 0.17471741 0.20071137 0.16605472\n",
      " 0.17941506 0.16801947 0.13371301 0.11623247 0.15285757 0.18039311\n",
      " 0.19194701 0.15810691 0.15770749 0.14934526 0.1616777  0.17658674\n",
      " 0.20489205 0.21232063 0.26093249 0.26004309 0.20146081 0.24846473\n",
      " 0.2849262  0.22785772 0.19972113 0.17469119 0.19865496 0.18925713\n",
      " 0.25045102 0.28154379 0.28894775 0.30908264 0.27206122 0.2455171\n",
      " 0.26183551 0.34511544 0.29299214 0.26944887 0.2140796  0.2659796\n",
      " 0.13593848 0.21183082 0.1809959  0.10004435 0.19033915 0.16070894\n",
      " 0.07303468 0.08965014 0.08143961 0.12012099 0.12410733 0.21655626]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Utilities from utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(data: pd.DataFrame, estimation: pd.DataFrame):\n",
    "    df_errors = (estimation - data)\n",
    "    df_rmse = ((df_errors) ** 2.0).mean(axis=0) ** 0.5\n",
    "    return df_rmse\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = MultiTaskElasticNetCV(cv=5)\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "    \n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"Future date must be greater than the current data's last date.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "    \n",
    "# Load and preprocess data\n",
    "df_data = pd.read_excel(\"C:/Thesis/03. Data/Final version data/Static.xlsx\", engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y').to_period('M')\n",
    "\n",
    "# Initialize the model\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "# Define the validation date and split the data\n",
    "DATE_VALIDATE = pd.Period('2010-01', freq='M')\n",
    "print(\"DATE_VALIDATE:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Date {DATE_VALIDATE} not found in dataframe columns\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "# Check the prepared datasets\n",
    "print((Y_train_PCA.shape, Y_train_other.shape, Y_reg_train.shape, \n",
    " Y_train_other_std.shape, Y_reg_train_std.shape))\n",
    "\n",
    "# Apply PCA and Yule-Walker estimation on the standardized data\n",
    "model.std_data = Y_train_other_std.T  # Ensure the same data subset is used for PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Check the results after applying PCA and Yule-Walker estimation\n",
    "pca_factors_shape = model.factors.shape\n",
    "yw_estimation_shape = model.phi.shape\n",
    "\n",
    "# Fit the ElasticNet model with cross-validation\n",
    "data_train = model.std_data[:, :int(model.std_data.shape[1] * 0.8)].T\n",
    "fac_train = model.factors.T[:int(model.factors.shape[1] * 0.8), :]\n",
    "\n",
    "B_matrix, r2_insample, intercept = model.enet_fit(data_train, fac_train)\n",
    "\n",
    "# Check the results after fitting ElasticNet with cross-validation\n",
    "B_matrix_shape = B_matrix.shape\n",
    "r2_insample_value = r2_insample\n",
    "intercept_value = intercept\n",
    "\n",
    "(pca_factors_shape, yw_estimation_shape, B_matrix_shape, r2_insample_value, intercept_value)\n",
    "\n",
    "# Validation Data\n",
    "data_validate = model.std_data[:, int(model.std_data.shape[1] * 0.8):].T\n",
    "fac_validate = model.factors.T[int(model.factors.shape[1] * 0.8):, :]\n",
    "\n",
    "# Predict using the model\n",
    "y_hat_validate = model.enet_predict(fac_validate)\n",
    "\n",
    "# Compute RMSE for validation data\n",
    "rmse_value = RMSE(data_validate, y_hat_validate)\n",
    "\n",
    "# Check RMSE value\n",
    "print(f\"RMSE: {rmse_value}\")\n",
    "\n",
    "# RMSE waarden plotten\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(rmse_value)), rmse_value)\n",
    "plt.xlabel('Variable Index')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for Each Variable in the Validation Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data shape: (66, 347)\n",
      "Training up to: 1995-01\n",
      "Training up to: 1995-02\n",
      "Training up to: 1995-03\n",
      "Training up to: 1995-04\n",
      "Training up to: 1995-05\n",
      "Training up to: 1995-06\n",
      "Training up to: 1995-07\n",
      "Training up to: 1995-08\n",
      "Training up to: 1995-09\n",
      "Training up to: 1995-10\n",
      "Training up to: 1995-11\n",
      "Training up to: 1995-12\n",
      "Training up to: 1996-01\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (12, 9)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Future period must be greater than the current data's last period.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 174\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rmse_values\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Calculate RMSE using expanding window\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m rmse_values \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_expanding_window_rmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1995-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2010-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-11\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mprint\u001b[39m(rmse_values)\n",
      "Cell \u001b[1;32mIn[72], line 154\u001b[0m, in \u001b[0;36mcalculate_expanding_window_rmse\u001b[1;34m(model, start_date, end_date, prediction_date)\u001b[0m\n\u001b[0;32m    151\u001b[0m model\u001b[38;5;241m.\u001b[39menet_fit(data_train, fac_train)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Predict factors up to the prediction date\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m forecast_factors \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactor_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# Predict CPI_Australia for the prediction date\u001b[39;00m\n\u001b[0;32m    157\u001b[0m y_hat_predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39menet_predict(forecast_factors\u001b[38;5;241m.\u001b[39mT)\n",
      "Cell \u001b[1;32mIn[72], line 95\u001b[0m, in \u001b[0;36mDynamicFactorModel.factor_forecast\u001b[1;34m(self, future_period, scenarios)\u001b[0m\n\u001b[0;32m     93\u001b[0m current_period \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_data\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m future_period \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m current_period:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFuture period must be greater than the current data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms last period.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m num_months \u001b[38;5;241m=\u001b[39m (future_period\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m-\u001b[39m current_period\u001b[38;5;241m.\u001b[39myear) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m12\u001b[39m \u001b[38;5;241m+\u001b[39m future_period\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m-\u001b[39m current_period\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m     98\u001b[0m phi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mValueError\u001b[0m: Future period must be greater than the current data's last period."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Utilities from utils.py\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(data: pd.DataFrame, estimation: pd.DataFrame):\n",
    "    df_errors = (estimation - data)\n",
    "    df_rmse = ((df_errors) ** 2.0).mean(axis=0) ** 0.5\n",
    "    return df_rmse\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = MultiTaskElasticNetCV(cv=5)\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "    \n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        print(\"Shape of X before any operation:\", X.shape)\n",
    "        print(\"Shape of Y before any operation:\", Y.shape)\n",
    "\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Shape mismatch in number of columns: adjusting Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Shape mismatch in number of rows: adjusting Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"New shape of Y after adjustment:\", Y.shape)\n",
    "\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        print(\"Transposed Shape of X:\", X.T.shape)\n",
    "        print(\"Transposed Shape of Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"The number of rows in X and Y must be the same after transposing\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_period, scenarios=100):\n",
    "        current_period = self.df_data.columns[-1]\n",
    "        if future_period <= current_period:\n",
    "            raise ValueError(\"Future period must be greater than the current data's last period.\")\n",
    "        num_months = (future_period.year - current_period.year) * 12 + future_period.month - current_period.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "df_data = pd.read_excel(\"C:/Thesis/03. Data/Final version data/Static.xlsx\", engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y').to_period('M')\n",
    "\n",
    "# Initialize the model\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "# Function to calculate RMSE for expanding window\n",
    "def calculate_expanding_window_rmse(model, start_date, end_date, prediction_date):\n",
    "    prediction_period = pd.Period(prediction_date, freq='M')\n",
    "    start_period = pd.Period(start_date, freq='M')\n",
    "    end_period = pd.Period(end_date, freq='M')\n",
    "\n",
    "    if prediction_period not in df_data.columns:\n",
    "        raise ValueError(f\"Prediction date {prediction_period} not found in dataframe columns\")\n",
    "    \n",
    "    rmse_values = []\n",
    "    current_period = start_period\n",
    "\n",
    "    while current_period <= end_period:\n",
    "        print(f\"Training up to: {current_period}\")\n",
    "        date_index = df_data.columns.get_loc(current_period)\n",
    "        if date_index < 12:  # Ensure at least 12 months of data for initial training\n",
    "            current_period += 1\n",
    "            continue\n",
    "\n",
    "        Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "        REGRESSION_STEP = 12\n",
    "        Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "        Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "        Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "        Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "        model.std_data = Y_train_other_std.T\n",
    "        model.apply_pca()\n",
    "        model.yw_estimation()\n",
    "\n",
    "        data_train = model.std_data[:, :int(model.std_data.shape[1] * 0.8)].T\n",
    "        fac_train = model.factors.T[:int(model.factors.shape[1] * 0.8), :]\n",
    "\n",
    "        model.enet_fit(data_train, fac_train)\n",
    "\n",
    "        # Predict factors up to the prediction date\n",
    "        forecast_factors = model.factor_forecast(prediction_period)\n",
    "        \n",
    "        # Predict CPI_Australia for the prediction date\n",
    "        y_hat_predict = model.enet_predict(forecast_factors.T)\n",
    "        cpi_actual = df_data.loc['CPI_Australia', prediction_period]\n",
    "\n",
    "        # Ensure y_hat_predict has the correct dimensions\n",
    "        if len(y_hat_predict) == 0 or len(y_hat_predict.shape) == 1:\n",
    "            print(f\"Skipping prediction for {current_period}, due to mismatched prediction dimensions.\")\n",
    "            current_period += 1\n",
    "            continue\n",
    "\n",
    "        rmse = np.sqrt(np.mean((y_hat_predict[0] - cpi_actual) ** 2))\n",
    "        rmse_values.append(rmse)\n",
    "\n",
    "        current_period += 1\n",
    "\n",
    "    return rmse_values\n",
    "\n",
    "# Calculate RMSE using expanding window\n",
    "rmse_values = calculate_expanding_window_rmse(model, '1995-01', '2010-01', '2023-11')\n",
    "print(rmse_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 13: Woensdag 14:35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized data shape: (66, 347)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expanding_window_forecast() missing 1 required positional argument: 'prediction_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 113\u001b[0m\n\u001b[0;32m    110\u001b[0m model \u001b[38;5;241m=\u001b[39m DynamicFactorModel(df_data, num_factors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;66;03m# Calculate RMSE using expanding window\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m rmse_values \u001b[38;5;241m=\u001b[39m \u001b[43mexpanding_window_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1995-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2010-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2023-01\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m(rmse_values)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# Plot the RMSE values\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: expanding_window_forecast() missing 1 required positional argument: 'prediction_date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Utilities for data preprocessing and evaluation\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(actual, predicted):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = MultiTaskElasticNetCV(cv=5)\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "\n",
    "def expanding_window_forecast(model, df_data, start_date, end_date, prediction_date):\n",
    "    start_period = pd.Period(start_date, freq='M')\n",
    "    end_period = pd.Period(end_date, freq='M')\n",
    "    prediction_period = pd.Period(prediction_date, freq='M')\n",
    "\n",
    "    if prediction_period not in df_data.columns:\n",
    "        raise ValueError(f\"Prediction date {prediction_period} not found in dataframe columns\")\n",
    "\n",
    "    rmse_values = []\n",
    "    current_period = start_period\n",
    "\n",
    "    while current_period <= end_period:\n",
    "        print(f\"Training up to: {current_period}\")\n",
    "        date_index = df_data.columns.get_loc(current_period)\n",
    "        if date_index < 12:  # Ensure at least 12 months of data for initial training\n",
    "            current_period += 1\n",
    "            continue\n",
    "\n",
    "        # Prepare training data\n",
    "        Y_train_PCA = df_data.iloc[:, :date_index + 1]\n",
    "\n",
    "        REGRESSION_STEP = 12\n",
    "        Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "        Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "        Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "        Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "        model.std_data = Y_train_other_std.T\n",
    "        model.apply_pca()\n",
    "        model.yw_estimation()\n",
    "\n",
    "        data_train = model.std_data[:, :int(model.std_data.shape[1] * 0.8)].T\n",
    "        fac_train = model.factors.T[:int(model.factors.shape[1] * 0.8), :]\n",
    "\n",
    "        model.enet_fit(data_train, fac_train)\n",
    "\n",
    "        # Predict factors up to the prediction date\n",
    "        forecast_factors = model.factor_forecast(prediction_period)\n",
    "        \n",
    "        # Predict CPI_Australia for the prediction date\n",
    "        y_hat_predict = model.enet_predict(forecast_factors.T)\n",
    "        cpi_actual = df_data.loc['CPI_Australia', prediction_period]\n",
    "\n",
    "        if y_hat_predict.shape[0] > 0 and len(cpi_actual) > 0:\n",
    "            rmse = RMSE(cpi_actual, y_hat_predict[0])\n",
    "            rmse_values.append(rmse)\n",
    "\n",
    "        current_period += 1\n",
    "\n",
    "    return rmse_values\n",
    "\n",
    "# Load and preprocess data\n",
    "df_data = pd.read_excel(\"C:/Thesis/03. Data/Final version data/Static.xlsx\", engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y').to_period('M')\n",
    "\n",
    "# Initialize the model\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "# Calculate RMSE using expanding window\n",
    "rmse_values = expanding_window_forecast(model, '1995-01', '2010-01', '2023-01')\n",
    "print(rmse_values)\n",
    "\n",
    "# Plot the RMSE values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(rmse_values)), rmse_values, marker='o')\n",
    "plt.xlabel('Expanding Window Step')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE for Expanding Window Forecast')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['1995-01', '1995-02', '1995-03', '1995-04', '1995-05', '1995-06',\n",
      "             '1995-07', '1995-08', '1995-09', '1995-10',\n",
      "             ...\n",
      "             '2022-09', '2022-10', '2022-11', '2022-12', '2023-01', '2023-02',\n",
      "             '2023-03', '2023-04', '2023-05', '2023-06'],\n",
      "            dtype='period[M]', length=342)\n"
     ]
    }
   ],
   "source": [
    "print(df_data.columns[:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 14: Woensdag 15:07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even zonder expanding window, gewoon trainen tot 2010, dan nov 2023 voorspellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (66, 347)\n",
      "First 5 columns of the DataFrame:\n",
      "PeriodIndex(['1995-01', '1995-02', '1995-03', '1995-04', '1995-05'], dtype='period[M]')\n",
      "Last 5 columns of the DataFrame:\n",
      "PeriodIndex(['2023-07', '2023-08', '2023-09', '2023-10', '2023-11'], dtype='period[M]')\n",
      "Standardized data shape: (66, 347)\n",
      "PCA factors shape: (9, 54)\n",
      "Yule-Walker estimation shape: (10, 9)\n",
      "ElasticNet B_matrix shape: (301, 9)\n",
      "Current period: 2023-11, Future period: 2023-11\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Future period must be greater than the current data's last period.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 115\u001b[0m\n\u001b[0;32m    113\u001b[0m PREDICTION_DATE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2023-11\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    114\u001b[0m prediction_period \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mPeriod(PREDICTION_DATE, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 115\u001b[0m forecast_factors \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfactor_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_period\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Predict CPI_Australia for the prediction date\u001b[39;00m\n\u001b[0;32m    118\u001b[0m y_hat_predict \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39menet_predict(forecast_factors\u001b[38;5;241m.\u001b[39mT)\n",
      "Cell \u001b[1;32mIn[81], line 57\u001b[0m, in \u001b[0;36mDynamicFactorModel.factor_forecast\u001b[1;34m(self, future_period, scenarios)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent period: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_period\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Future period: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuture_period\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m future_period \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m current_period:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFuture period must be greater than the current data\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms last period.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m num_months \u001b[38;5;241m=\u001b[39m (future_period\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m-\u001b[39m current_period\u001b[38;5;241m.\u001b[39myear) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m12\u001b[39m \u001b[38;5;241m+\u001b[39m future_period\u001b[38;5;241m.\u001b[39mmonth \u001b[38;5;241m-\u001b[39m current_period\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m     60\u001b[0m phi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[1;31mValueError\u001b[0m: Future period must be greater than the current data's last period."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Utilities for data preprocessing and evaluation\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(actual, predicted):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Standardized data shape:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factors shape:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker estimation shape:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = MultiTaskElasticNetCV(cv=5)\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix shape:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "    \n",
    "    def factor_forecast(self, future_period, scenarios=100):\n",
    "        current_period = self.df_data.columns[-1]\n",
    "        print(f\"Current period: {current_period}, Future period: {future_period}\")\n",
    "        if future_period <= current_period:\n",
    "            raise ValueError(\"Future period must be greater than the current data's last period.\")\n",
    "        num_months = (future_period.year - current_period.year) * 12 + future_period.month - current_period.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "\n",
    "# Load and preprocess data\n",
    "df_data = pd.read_excel(\"C:/Thesis/03. Data/Final version data/Static.xlsx\", engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y').to_period('M')\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(f\"DataFrame shape: {df_data.shape}\")\n",
    "\n",
    "# Print the first 5 columns and the last 5 columns to verify\n",
    "print(\"First 5 columns of the DataFrame:\")\n",
    "print(df_data.columns[:5])\n",
    "print(\"Last 5 columns of the DataFrame:\")\n",
    "print(df_data.columns[-5:])\n",
    "\n",
    "# Initialize the model\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "# Train the model on data from 1995 to 2020\n",
    "DATE_TRAIN_END = pd.Period('2020-01', freq='M')\n",
    "if DATE_TRAIN_END not in df_data.columns:\n",
    "    raise ValueError(f\"Training end date {DATE_TRAIN_END} not found in dataframe columns\")\n",
    "\n",
    "date_index = df_data.columns.get_loc(DATE_TRAIN_END)\n",
    "Y_train_PCA = df_data.iloc[:, :date_index + 1]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "model.std_data = Y_train_other_std.T\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Use all data up to DATE_TRAIN_END for training\n",
    "data_train = model.std_data.T\n",
    "fac_train = model.factors.T\n",
    "\n",
    "model.enet_fit(data_train, fac_train)\n",
    "\n",
    "# Predict for November 2023\n",
    "PREDICTION_DATE = '2023-11'\n",
    "prediction_period = pd.Period(PREDICTION_DATE, freq='M')\n",
    "forecast_factors = model.factor_forecast(prediction_period)\n",
    "\n",
    "# Predict CPI_Australia for the prediction date\n",
    "y_hat_predict = model.enet_predict(forecast_factors.T)\n",
    "cpi_actual = df_data.loc['CPI_Australia', prediction_period]\n",
    "\n",
    "# Ensure y_hat_predict has the correct dimensions and calculate RMSE\n",
    "if y_hat_predict.shape[0] > 0 and len(cpi_actual) > 0:\n",
    "    rmse = RMSE(cpi_actual, y_hat_predict[0])\n",
    "    print(f\"RMSE for CPI_Australia on {PREDICTION_DATE}: {rmse}\")\n",
    "else:\n",
    "    print(f\"Prediction dimensions mismatch or missing actual data for {PREDICTION_DATE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versie 15: Woensdag 15:35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gaan weer verder met versie 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gestandaardiseerde data vorm: (66, 347)\n",
      "VALIDATIEDATUM: 2010-01\n",
      "((66, 180), (54, 180), (66, 169), (54, 180), (66, 169))\n",
      "PCA factoren vorm: (9, 54)\n",
      "Yule-Walker schatting vorm: (10, 9)\n",
      "ElasticNet B_matrix vorm: (180, 9)\n",
      "RMSE: [0.34540093 0.25503345 0.30784261 0.30565958 0.23967187 0.30148706\n",
      " 0.2574635  0.23799561 0.24229224 0.21184805 0.2395499  0.25038898\n",
      " 0.20970424 0.22180457 0.15270446 0.21198822 0.20914793 0.14661331\n",
      " 0.16021209 0.14500789 0.20079238 0.16623088 0.17889684 0.16676639\n",
      " 0.15696864 0.19615548 0.20479252 0.24594497 0.20859949 0.17645157\n",
      " 0.14118905 0.25968953 0.16137724 0.21210136 0.13436814 0.15384759\n",
      " 0.17726176 0.18577161 0.23552222 0.23003837 0.13582258 0.17038916\n",
      " 0.15141175 0.20457154 0.2021699  0.25285294 0.27132298 0.27583883\n",
      " 0.22778871 0.2489437  0.17845143 0.20094289 0.21110068 0.1938872\n",
      " 0.23349201 0.29098672 0.22088326 0.21526476 0.18435644 0.15868665\n",
      " 0.20141707 0.15246414 0.20647296 0.13419565 0.14623452 0.13790227\n",
      " 0.15323414 0.1302494  0.17851331 0.19124412 0.15696224 0.09614018\n",
      " 0.17442745 0.19530938 0.18804463 0.24807925 0.22116813 0.22260066\n",
      " 0.21105695 0.19791918 0.15019742 0.23017892 0.25833022 0.22857165\n",
      " 0.23443901 0.23150501 0.24706304 0.18867818 0.18328172 0.16417723\n",
      " 0.12406814 0.2387401  0.19662601 0.30288398 0.22541077 0.1503673\n",
      " 0.15389637 0.18505125 0.18996455 0.24602198 0.19778565 0.15974929\n",
      " 0.11272114 0.13663689 0.13123504 0.17899246 0.15488258 0.1598909\n",
      " 0.15767774 0.16297806 0.18181297 0.25482374 0.29359975 0.30059507\n",
      " 0.2174752  0.21379172 0.18101924 0.18764505 0.12258891 0.16689757\n",
      " 0.12116896 0.12409925 0.15435959 0.15650704 0.14827317 0.15619245\n",
      " 0.1451166  0.14913978 0.16270063 0.17471741 0.20071137 0.16605472\n",
      " 0.17941506 0.16801947 0.13371301 0.11623247 0.15285757 0.18039311\n",
      " 0.19194701 0.15810691 0.15770749 0.14934526 0.1616777  0.17658674\n",
      " 0.20489205 0.21232063 0.26093249 0.26004309 0.20146081 0.24846473\n",
      " 0.2849262  0.22785772 0.19972113 0.17469119 0.19865496 0.18925713\n",
      " 0.25045102 0.28154379 0.28894775 0.30908264 0.27206122 0.2455171\n",
      " 0.26183551 0.34511544 0.29299214 0.26944887 0.2140796  0.2659796\n",
      " 0.13593848 0.21183082 0.1809959  0.10004435 0.19033915 0.16070894\n",
      " 0.07303468 0.08965014 0.08143961 0.12012099 0.12410733 0.21655626]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import MultiTaskElasticNetCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "# Functies voor standaardisatie en RMSE berekening\n",
    "def standardize(variables):\n",
    "    central = (variables - variables.mean())\n",
    "    return central / central.std()\n",
    "\n",
    "def RMSE(data: pd.DataFrame, estimation: pd.DataFrame):\n",
    "    df_errors = (estimation - data)\n",
    "    df_rmse = ((df_errors) ** 2.0).mean(axis=0) ** 0.5\n",
    "    return df_rmse\n",
    "\n",
    "# Dynamic Factor Model klasse\n",
    "class DynamicFactorModel:\n",
    "    def __init__(self, df_data, num_factors):\n",
    "        self.df_data = df_data\n",
    "        self.num_factors = num_factors\n",
    "        self.std_data = standardize(df_data.values.T).T\n",
    "        print(\"Gestandaardiseerde data vorm:\", self.std_data.shape)\n",
    "        self.pca = PCA(n_components=num_factors)\n",
    "        self.factors = None\n",
    "        self.phi = None\n",
    "        self.B_mat = None\n",
    "        self.model_ena = None\n",
    "\n",
    "    def apply_pca(self):\n",
    "        self.factors = self.pca.fit_transform(self.std_data.T).T\n",
    "        print(\"PCA factoren vorm:\", self.factors.shape)\n",
    "\n",
    "    def yw_estimation(self):\n",
    "        model = sm.tsa.VAR(self.factors.T)\n",
    "        results = model.fit(1)\n",
    "        self.phi = results.params\n",
    "        print(\"Yule-Walker schatting vorm:\", self.phi.shape)\n",
    "\n",
    "    def enet_fit(self, data_train, fac_train):\n",
    "        self.model_ena = MultiTaskElasticNetCV(cv=5)\n",
    "        self.model_ena.fit(fac_train, data_train)\n",
    "        self.B_mat = self.model_ena.coef_\n",
    "        x_hat = self.model_ena.predict(fac_train)\n",
    "        intercept = self.model_ena.intercept_\n",
    "        r2_insample = r2_score(data_train, x_hat)\n",
    "        print(\"ElasticNet B_matrix vorm:\", self.B_mat.shape)\n",
    "        return self.B_mat, r2_insample, intercept\n",
    "\n",
    "    def enet_predict(self, fac_predict):\n",
    "        x_hat = self.model_ena.predict(fac_predict)\n",
    "        return x_hat\n",
    "    \n",
    "    def autoregression(self, data_train_reg, fac_train, beta_const):\n",
    "        X = data_train_reg.T\n",
    "        Y = (self.std_data.T - np.dot(fac_train, self.B_mat.T) - beta_const).T\n",
    "\n",
    "        print(\"Vorm van X voor enige operatie:\", X.shape)\n",
    "        print(\"Vorm van Y voor enige operatie:\", Y.shape)\n",
    "\n",
    "        if X.shape[1] != Y.shape[1]:\n",
    "            print(\"Vorm mismatch in aantal kolommen: aanpassen van Y\")\n",
    "            Y = Y[:, :X.shape[1]]\n",
    "            print(\"Nieuwe vorm van Y na aanpassing:\", Y.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            print(\"Vorm mismatch in aantal rijen: aanpassen van Y\")\n",
    "            Y = Y[:X.shape[0], :]\n",
    "            print(\"Nieuwe vorm van Y na aanpassing:\", Y.shape)\n",
    "\n",
    "        Y = np.matrix(Y)\n",
    "        X = np.matrix(X)\n",
    "\n",
    "        print(\"Getransponeerde vorm van X:\", X.T.shape)\n",
    "        print(\"Getransponeerde vorm van Y:\", Y.T.shape)\n",
    "\n",
    "        if X.shape[0] != Y.shape[0]:\n",
    "            raise ValueError(\"Het aantal rijen in X en Y moet gelijk zijn na transponeren\")\n",
    "\n",
    "        model = sm.OLS(Y, X)\n",
    "        results = model.fit()\n",
    "        return results.params\n",
    "\n",
    "    def dfm_fit_pcayw(self, data_train, data_train_reg):\n",
    "        self.apply_pca()\n",
    "        self.yw_estimation()\n",
    "        self.B_mat, r2_insample, beta_const = self.enet_fit(data_train, self.factors.T)\n",
    "        C_matrix = self.autoregression(data_train_reg, self.factors.T, beta_const)\n",
    "        return self.B_mat, C_matrix, r2_insample, beta_const\n",
    "\n",
    "    def factor_forecast(self, future_date, scenarios=100):\n",
    "        future_date = datetime.strptime(future_date, '%d/%m/%Y')\n",
    "        current_date = self.df_data.columns[-1]\n",
    "        if future_date <= current_date:\n",
    "            raise ValueError(\"De toekomstige datum moet later zijn dan de laatste datum in de data.\")\n",
    "        num_months = (future_date.year - current_date.year) * 12 + future_date.month - current_date.month\n",
    "        \n",
    "        phi = self.phi[1:].T\n",
    "        intercept = self.phi[0]\n",
    "        factors_forecast = []\n",
    "        factors = self.factors.T[-1]\n",
    "        \n",
    "        for _ in range(num_months):\n",
    "            factors = np.dot(phi, factors) + intercept\n",
    "            factors_forecast.append(factors)\n",
    "        \n",
    "        return np.array(factors_forecast)\n",
    "    \n",
    "# Data inladen en voorbewerken\n",
    "file_path = 'C:/Thesis/03. Data/Final version data/Static.xlsx'\n",
    "df_data = pd.read_excel(file_path, engine='openpyxl', index_col=0)\n",
    "df_data.columns = pd.to_datetime(df_data.columns, format='%d/%m/%Y').to_period('M')\n",
    "\n",
    "# Initialiseer het model\n",
    "model = DynamicFactorModel(df_data, num_factors=9)\n",
    "\n",
    "# Bepaal de validatiedatum en splits de data\n",
    "DATE_VALIDATE = pd.Period('2010-01', freq='M')\n",
    "print(\"VALIDATIEDATUM:\", DATE_VALIDATE)\n",
    "\n",
    "if DATE_VALIDATE in df_data.columns:\n",
    "    date_index = df_data.columns.get_loc(DATE_VALIDATE)\n",
    "else:\n",
    "    raise ValueError(f\"Datum {DATE_VALIDATE} niet gevonden in de kolommen van de dataframe\")\n",
    "\n",
    "Y_train_PCA = df_data.iloc[:, :date_index]\n",
    "\n",
    "REGRESSION_STEP = 12\n",
    "Y_train_other = Y_train_PCA.iloc[REGRESSION_STEP:, :]\n",
    "Y_reg_train = df_data.iloc[:, :date_index + 1 - REGRESSION_STEP]\n",
    "\n",
    "Y_train_other_std = standardize(Y_train_other.values.T).T\n",
    "Y_reg_train_std = standardize(Y_reg_train.values.T).T\n",
    "\n",
    "# Controleer de voorbereide datasets\n",
    "print((Y_train_PCA.shape, Y_train_other.shape, Y_reg_train.shape, \n",
    " Y_train_other_std.shape, Y_reg_train_std.shape))\n",
    "\n",
    "# Voer PCA en Yule-Walker schatting uit op de gestandaardiseerde data\n",
    "model.std_data = Y_train_other_std.T  # Zorg ervoor dat dezelfde subset data wordt gebruikt voor PCA\n",
    "model.apply_pca()\n",
    "model.yw_estimation()\n",
    "\n",
    "# Controleer de resultaten na het toepassen van PCA en Yule-Walker schatting\n",
    "pca_factors_shape = model.factors.shape\n",
    "yw_estimation_shape = model.phi.shape\n",
    "\n",
    "# Pas het ElasticNet-model aan met cross-validatie\n",
    "data_train = model.std_data[:, :int(model.std_data.shape[1] * 0.8)].T\n",
    "fac_train = model.factors.T[:int(model.factors.shape[1] * 0.8), :]\n",
    "\n",
    "B_matrix, r2_insample, intercept = model.enet_fit(data_train, fac_train)\n",
    "\n",
    "# Controleer de resultaten na het aanpassen van ElasticNet met cross-validatie\n",
    "B_matrix_shape = B_matrix.shape\n",
    "r2_insample_value = r2_insample\n",
    "intercept_value = intercept\n",
    "\n",
    "(pca_factors_shape, yw_estimation_shape, B_matrix_shape, r2_insample_value, intercept_value)\n",
    "\n",
    "# Validatie Data\n",
    "data_validate = model.std_data[:, int(model.std_data.shape[1] * 0.8):].T\n",
    "fac_validate = model.factors.T[int(model.factors.shape[1] * 0.8):, :]\n",
    "\n",
    "# Voorspel met het model\n",
    "y_hat_validate = model.enet_predict(fac_validate)\n",
    "\n",
    "# Bereken RMSE voor validatie data\n",
    "rmse_value = RMSE(data_validate, y_hat_validate)\n",
    "\n",
    "# Controleer de RMSE waarde\n",
    "print(f\"RMSE: {rmse_value}\")\n",
    "\n",
    "# Plot RMSE waarden\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(rmse_value)), rmse_value)\n",
    "plt.xlabel('Variabele Index')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('RMSE voor Elke Variabele in de Validatieset')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
